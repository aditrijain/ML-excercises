{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b9003b",
   "metadata": {},
   "source": [
    "Implement the forward propagation for a two-hidden-layer network for m-samples and n-features, as we discussed in class. Initialize the weights randomly. Use the data from the previous labs, such as logistic regression. You can choose the number of neurons in the hidden layer and use the sigmoid activation function. Report the evaluation metrics for the network.  Also, use other non-linear activation functions like ReLU and Tanh. Report the loss using both MSE and Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ef75e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adikw\\AppData\\Local\\Temp\\ipykernel_40116\\1915285723.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Rain'] = df['Rain'].replace(['rain', 'no rain'], [1, 0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('weather_forecast_data.csv', header=0)\n",
    "\n",
    "df['Rain'] = df['Rain'].replace(['rain', 'no rain'], [1, 0])\n",
    "Y = df['Rain'].to_numpy()\n",
    "\n",
    "def normalize(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['Rain']:\n",
    "        df[col] = normalize(df[col])\n",
    "\n",
    "X = df.drop(columns=['Rain']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fab271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss for sigmoid : 1103.2232858961079\n",
      "Cross Entropy Loss for tanh : 1311.8836731214656\n",
      "Cross Entropy Loss for relU : 5784.093775461044\n",
      "MSE Loss for sigmoid: 0.06641516570411896\n",
      "MSE Loss for tanh: 0.06785708138207433\n",
      "MSE Loss for relU: 0.06279999874400005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adikw\\AppData\\Local\\Temp\\ipykernel_40116\\2826510578.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Rain'] = df['Rain'].replace(['rain', 'no rain'], [1, 0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "J=lambda A, Y: -1 * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) #cross entropy \n",
    "Z=lambda W, X, b: np.dot(W, X) + b\n",
    "sigmoid=lambda Z: 1 / (1 + np.exp(-Z)) \n",
    "tanh=lambda Z: (np.tanh(Z) + 1.0) / 2.0\n",
    "relu=lambda Z: np.clip(\n",
    "    np.maximum(0, Z) / (np.max(np.maximum(0, Z)) + 1e-8),\n",
    "    1e-8,\n",
    "    1 - 1e-8)\n",
    "mse=lambda A,Y:1/(2*Y.shape[0]) * np.sum(np.square(A - Y)) #mse\n",
    "\n",
    "def calc_sig(W, X, b):\n",
    "    z = Z(W, X, b)\n",
    "    A = sigmoid(z)\n",
    "    return A\n",
    "def calc_tanh(W, X, b):\n",
    "    z = Z(W, X, b)\n",
    "    A=tanh(z)\n",
    "    return A\n",
    "def calc_relU(W, X, b):\n",
    "    z = Z(W, X, b)\n",
    "    a=relu(z)\n",
    "    return a\n",
    "\n",
    "def neuralnet(num_hidden_neurons, X, Y, alpha, thresh):\n",
    "    n_x = X.shape[0]  \n",
    "   \n",
    "    W1 = np.random.randn(num_hidden_neurons, n_x) \n",
    "    b1 = np.zeros((num_hidden_neurons, 1))                \n",
    "    W2 = np.random.randn(1, num_hidden_neurons) \n",
    "    b2 = np.zeros((1, 1))                                 \n",
    "    \n",
    "    A1_sig=calc_sig(W1,X,b1)\n",
    "    A1_tanh=calc_tanh(W1,X,b1)\n",
    "    A1_relu=calc_relU(W1,X,b1)\n",
    "    A2_sig=calc_sig(W2,A1_sig,b2)\n",
    "    A2_tanh=calc_tanh(W2,A1_tanh,b2)\n",
    "    A2_relu=calc_relU(W2,A1_relu,b2)\n",
    "    \n",
    "    \n",
    "    cost_cross_entropy_sig = J(A2_sig, Y)\n",
    "    cost_cross_entropy_tanh = J(A2_tanh, Y)\n",
    "    cost_cross_entropy_relU = J(A2_relu, Y)\n",
    "    cost_MSE_sig = mse(A2_sig, Y)\n",
    "    cost_MSE_tanh = mse(A2_tanh, Y)\n",
    "    cost_MSE_relu = mse(A2_relu, Y)\n",
    "    print(f\"Cross Entropy Loss for sigmoid : {cost_cross_entropy_sig}\")\n",
    "    print(f\"Cross Entropy Loss for tanh : {cost_cross_entropy_tanh}\")\n",
    "    print(f\"Cross Entropy Loss for relU : {cost_cross_entropy_relU}\")\n",
    "    print(f\"MSE Loss for sigmoid: {cost_MSE_sig}\")\n",
    "    print(f\"MSE Loss for tanh: {cost_MSE_tanh}\")\n",
    "    print(f\"MSE Loss for relU: {cost_MSE_relu}\")\n",
    "\n",
    "df = pd.read_csv('weather_forecast_data.csv', header=0)\n",
    "\n",
    "df['Rain'] = df['Rain'].replace(['rain', 'no rain'], [1, 0])\n",
    "Y = df['Rain'].to_numpy()\n",
    "\n",
    "def normalize(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['Rain']:\n",
    "        df[col] = normalize(df[col])\n",
    "\n",
    "X = df.drop(columns=['Rain']).to_numpy()\n",
    "\n",
    "\n",
    "params = neuralnet(4, X.T, Y.T,0.1,10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
