{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Set size of figure\n",
        "plt.rcParams['figure.figsize'] = [8, 8]\n",
        "# Set size of font\n",
        "plt.rcParams['font.size'] = 10"
      ],
      "metadata": {
        "id": "FasmVZvHPgMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GMM\n",
        "\n",
        "Now that we know how to sample from simple distributions like the Bernoulli and Gaussian, we shall move to sampling from a GMM. There are two steps here:\n",
        "\n",
        "- Pick a mixture $k$ from $K$ mixtures based on the categorical distribution governing it\n",
        "- Sample a point from the $k^{th}$ Gaussian"
      ],
      "metadata": {
        "id": "7A9Gri4ZP1oK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-1\n",
        "\n",
        "Consider a GMM with $K = 3$. The mixture probabilities are given below. It is easier to work with zero-indexing, hence we will index our mixtures starting from $0$:\n",
        "\n",
        "$$\n",
        "\\pi_0 = 0.3\\\\\n",
        "\\pi_1 = 0.5\\\\\n",
        "\\pi_2 = 0.2\n",
        "$$\n",
        "\n",
        "Perform step-1 of the sampling process by choosing one of the three mixtures based on the above distribution. Call this value $k$. Use the cell given below for all your computation. Do not change the seed value. Enter $k$ as your answer."
      ],
      "metadata": {
        "id": "1GlVAG9-8qFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### RNG ###\n",
        "rng = np.random.default_rng(seed = 1001)\n",
        "### Solution ###\n"
      ],
      "metadata": {
        "id": "aQqjseA3RYkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a19caa-85b9-4491-d958-0003ea29e0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-2\n",
        "\n",
        "Now we move to step-2 of the sampling process. Sample a point from mixture $k$ (obtained from the previous question). The means and variances of the mixtures are as follows:\n",
        "\n",
        "$$\n",
        "\\mu_1 = -4, \\sigma_1^2 = 2\\\\\n",
        "\\mu_2 = 0, \\sigma_2^2 = 1\\\\\n",
        "\\mu_3 = 5, \\sigma_3^2 = 3\n",
        "$$\n",
        "\n",
        "\n",
        "Use the cell given below for all your computation. Enter the sampled point correct to three decimal places."
      ],
      "metadata": {
        "id": "4hd29e0n9mar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### RNG ###\n",
        "rng = np.random.default_rng(seed = 1001)\n",
        "### Solution ###\n",
        "means = [-4, 0, 5]\n",
        "variances = [2, 1, 3]\n",
        "# k is from the previous cell's execution output\n",
        "# I will hardcode the value of k as 1, which was the output of the previous cell.\n",
        "k = 1\n",
        "sampled_point = rng.normal(loc=means[k], scale=np.sqrt(variances[k]))\n",
        "print(f\"{sampled_point:.3f}\")"
      ],
      "metadata": {
        "id": "D0TUgnKG91t2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a83c1f-45d2-42df-e62f-1487e228dfa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-3\n",
        "\n",
        "Now that we have sampled one point, we are ready to do more. Sample $100,000$ points from the GMM. Generate each point step by step. Store the samples in a NumPy array `X` of shape $(100,000, )$. `X[i]` should hold the value of the $i^{th}$ point generated from the GMM.  Use the cell below for all your computation. Enter the mean of `X` as your answer correct to three decimal places."
      ],
      "metadata": {
        "id": "7FnbGy4p-jeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### RNG ###\n",
        "rng = np.random.default_rng(seed = 1001)\n",
        "### Solution ###\n",
        "num_samples = 100000\n",
        "probabilities = [0.3, 0.5, 0.2]\n",
        "means = [-4, 0, 5]\n",
        "variances = [2, 1, 3]\n",
        "\n",
        "X = np.zeros(num_samples)\n",
        "\n",
        "for i in range(num_samples):\n",
        "    k = rng.choice(3, p=probabilities)\n",
        "    X[i] = rng.normal(loc=means[k], scale=np.sqrt(variances[k]))\n",
        "\n",
        "print(f\"{np.mean(X):.3f}\")"
      ],
      "metadata": {
        "id": "XA8gv2jq-rTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912e63b3-a355-4767-f6fe-921acadfbeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-4\n",
        "\n",
        "Plot a histogram of the dataset. Play around with the `bins` parameter of the `plt.hist` method. We will be using this dataset `X` all through the next section of the colab."
      ],
      "metadata": {
        "id": "2heXmKhI_uXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "plt.hist(X,bins=1000)"
      ],
      "metadata": {
        "id": "lpor62HP_xPF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e6bf16e-43dc-4054-9669-dbca450ac8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   0.,\n",
              "          2.,   0.,   0.,   1.,   2.,   2.,   1.,   4.,   0.,   0.,   0.,\n",
              "          0.,   1.,   0.,   0.,   1.,   0.,   1.,   1.,   3.,   2.,   1.,\n",
              "          1.,   0.,   2.,   2.,   3.,   3.,   2.,   1.,   2.,   2.,   3.,\n",
              "          0.,   2.,   2.,   1.,   3.,   4.,   4.,   3.,   4.,   3.,   4.,\n",
              "          1.,   3.,   5.,   2.,  10.,   9.,   4.,   4.,   3.,   4.,   9.,\n",
              "          9.,   8.,   8.,   5.,   7.,   8.,  10.,   7.,   8.,   9.,  13.,\n",
              "          8.,   8.,  10.,  13.,  15.,  10.,   7.,  10.,   7.,  16.,  13.,\n",
              "         16.,  16.,  15.,  16.,  11.,  25.,  18.,  20.,  10.,  19.,  14.,\n",
              "         23.,  29.,  26.,  20.,  23.,  30.,  15.,  25.,  15.,  30.,  25.,\n",
              "         19.,  31.,  26.,  23.,  34.,  46.,  34.,  29.,  49.,  28.,  30.,\n",
              "         46.,  45.,  26.,  59.,  39.,  45.,  46.,  50.,  41.,  62.,  55.,\n",
              "         46.,  61.,  45.,  63.,  49.,  54.,  47.,  47.,  66.,  60.,  58.,\n",
              "         79.,  63.,  58.,  50.,  62.,  62.,  83.,  65.,  63.,  76.,  70.,\n",
              "         91., 103.,  80., 100.,  88.,  81.,  87.,  97.,  96.,  91.,  87.,\n",
              "         93., 101.,  85.,  93., 100., 121., 113., 118., 112., 116., 124.,\n",
              "        103., 129., 127., 125., 118., 124., 143., 118., 139., 147., 120.,\n",
              "        145., 129., 153., 133., 123., 154., 140., 148., 127., 164., 139.,\n",
              "        157., 136., 169., 164., 154., 156., 185., 139., 159., 140., 147.,\n",
              "        149., 157., 157., 148., 177., 170., 175., 176., 180., 185., 180.,\n",
              "        173., 162., 176., 148., 181., 158., 174., 181., 182., 186., 179.,\n",
              "        170., 195., 172., 185., 188., 187., 172., 183., 187., 197., 183.,\n",
              "        179., 159., 171., 185., 174., 197., 190., 186., 188., 174., 176.,\n",
              "        190., 195., 174., 177., 169., 182., 166., 190., 155., 164., 158.,\n",
              "        192., 188., 162., 173., 165., 163., 173., 183., 169., 164., 175.,\n",
              "        159., 137., 159., 159., 150., 147., 132., 157., 134., 150., 149.,\n",
              "        150., 119., 136., 132., 131., 134., 122., 142., 138., 165., 114.,\n",
              "        125., 137., 148., 121., 131., 144., 119., 112., 133., 138., 113.,\n",
              "        116., 130., 123.,  95., 108., 140., 123., 123., 107.,  95., 112.,\n",
              "        110., 123., 117., 107., 127., 130., 130., 138., 121., 133., 116.,\n",
              "        123., 118., 136., 135., 126., 125., 122., 127., 148., 112., 145.,\n",
              "        154., 120., 150., 140., 150., 138., 162., 166., 162., 167., 142.,\n",
              "        155., 183., 157., 180., 158., 187., 200., 203., 198., 180., 216.,\n",
              "        213., 202., 203., 235., 217., 224., 223., 250., 227., 231., 253.,\n",
              "        261., 252., 257., 256., 288., 305., 293., 279., 312., 309., 333.,\n",
              "        314., 299., 294., 312., 319., 348., 343., 319., 355., 340., 341.,\n",
              "        350., 351., 370., 388., 368., 333., 407., 390., 393., 400., 402.,\n",
              "        398., 412., 386., 395., 413., 426., 429., 429., 419., 418., 385.,\n",
              "        426., 448., 451., 469., 492., 397., 447., 436., 409., 423., 428.,\n",
              "        420., 458., 438., 433., 406., 428., 438., 425., 417., 424., 442.,\n",
              "        406., 384., 409., 399., 394., 423., 363., 385., 364., 384., 396.,\n",
              "        400., 369., 375., 348., 354., 365., 333., 326., 341., 349., 336.,\n",
              "        329., 316., 312., 305., 310., 304., 276., 275., 310., 261., 246.,\n",
              "        239., 210., 261., 260., 231., 254., 233., 209., 223., 216., 216.,\n",
              "        182., 192., 223., 167., 145., 180., 165., 191., 184., 159., 169.,\n",
              "        159., 148., 120., 131., 143., 153., 133., 151., 120., 122.,  97.,\n",
              "        113., 102., 102., 119.,  88., 112.,  83.,  91.,  85.,  90.,  89.,\n",
              "         93.,  96.,  84.,  70.,  74.,  67.,  81.,  73.,  63.,  60.,  56.,\n",
              "         72.,  60.,  70.,  57.,  48.,  51.,  68.,  61.,  51.,  61.,  48.,\n",
              "         61.,  48.,  46.,  42.,  53.,  52.,  43.,  57.,  62.,  50.,  65.,\n",
              "         47.,  46.,  39.,  60.,  53.,  53.,  50.,  48.,  52.,  54.,  45.,\n",
              "         58.,  38.,  50.,  49.,  55.,  52.,  59.,  50.,  49.,  71.,  51.,\n",
              "         73.,  53.,  64.,  71.,  80.,  49.,  61.,  50.,  63.,  56.,  81.,\n",
              "         59.,  64.,  57.,  53.,  70.,  67.,  73.,  60.,  86.,  67.,  75.,\n",
              "         68.,  84.,  74.,  56.,  67.,  85.,  78.,  97.,  83.,  76.,  85.,\n",
              "         65.,  66.,  85.,  70.,  69.,  82., 107.,  87.,  82.,  75.,  88.,\n",
              "         92.,  73.,  75.,  87.,  75.,  98.,  95.,  90.,  89.,  96.,  87.,\n",
              "         77.,  84.,  82., 103.,  75.,  88.,  98.,  90.,  93.,  91.,  81.,\n",
              "         95., 107.,  96.,  94.,  93.,  78.,  99., 100.,  95.,  99.,  92.,\n",
              "        128.,  86.,  92.,  95.,  98.,  88., 105., 107.,  97.,  92., 101.,\n",
              "        107.,  94., 105.,  85., 102.,  79.,  97.,  92.,  90., 105., 104.,\n",
              "         87., 107.,  99.,  89.,  78., 107., 103.,  78.,  94., 112.,  99.,\n",
              "        121., 112.,  95.,  88., 100.,  99., 106., 100.,  99., 112.,  78.,\n",
              "         99.,  98.,  88.,  84.,  81.,  83.,  84.,  78.,  75.,  91.,  87.,\n",
              "         85.,  96.,  76.,  86.,  70.,  80.,  75.,  72.,  81.,  76.,  86.,\n",
              "         72.,  72.,  81.,  78.,  68.,  67.,  94.,  82.,  75.,  59.,  83.,\n",
              "         68.,  66.,  57.,  61.,  91.,  72.,  50.,  61.,  64.,  73.,  54.,\n",
              "         63.,  47.,  51.,  69.,  63.,  63.,  59.,  57.,  61.,  65.,  55.,\n",
              "         61.,  58.,  48.,  46.,  62.,  47.,  48.,  59.,  63.,  38.,  51.,\n",
              "         37.,  40.,  48.,  42.,  49.,  41.,  34.,  37.,  46.,  47.,  41.,\n",
              "         32.,  42.,  47.,  44.,  31.,  21.,  31.,  38.,  33.,  37.,  28.,\n",
              "         32.,  27.,  29.,  28.,  31.,  32.,  31.,  24.,  19.,  38.,  23.,\n",
              "         20.,  19.,  31.,  33.,  17.,  29.,  19.,  25.,  21.,  22.,  15.,\n",
              "         31.,  23.,  13.,  19.,  17.,  13.,  23.,  22.,  16.,   9.,  13.,\n",
              "         25.,  11.,  13.,  15.,  14.,  17.,  19.,  19.,  14.,   8.,  15.,\n",
              "         15.,   7.,  20.,  12.,   9.,  17.,   7.,   6.,  13.,  10.,   9.,\n",
              "          9.,   8.,  15.,   5.,  10.,   8.,   8.,   6.,  12.,   3.,   5.,\n",
              "          7.,   7.,  12.,   5.,   8.,   6.,   7.,   3.,   5.,   6.,   6.,\n",
              "          7.,   6.,   5.,   4.,   4.,   3.,   2.,   7.,   1.,   3.,   3.,\n",
              "          7.,   1.,   3.,   2.,   5.,   2.,   2.,   6.,   5.,   3.,   3.,\n",
              "          2.,   3.,   2.,   2.,   4.,   3.,   1.,   2.,   3.,   5.,   2.,\n",
              "          1.,   0.,   1.,   2.,   3.,   1.,   0.,   2.,   1.,   1.,   0.,\n",
              "          0.,   2.,   1.,   1.,   0.,   1.,   1.,   1.,   1.,   0.,   0.,\n",
              "          1.,   1.,   0.,   1.,   1.,   1.,   0.,   1.,   0.,   1.,   0.,\n",
              "          1.,   1.,   0.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "          2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   1.]),\n",
              " array([-9.31716939, -9.29582454, -9.2744797 , ..., 11.98498411,\n",
              "        12.00632895, 12.0276738 ]),\n",
              " <BarContainer object of 1000 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EM algorithm\n",
        "\n",
        "It is time to start coding up the EM algorithm from scratch. We will break this down into five stages:\n",
        "\n",
        "- Initialization\n",
        "- E-step\n",
        "- M-step\n",
        "- Stopping criterion\n",
        "- Algorithm\n",
        "\n",
        "For each of the first four stages, we will write functions that are related to that stage. All these functions will be eventually used in the code for the EM algorithm. This is a modular approach to writing the code. We have identified four blocks or stages. We can independently work on these four blocks and finally combine them. If something goes wrong, we can quickly localize the problem to one of these four blocks.\n"
      ],
      "metadata": {
        "id": "t1VFwTY0ArhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-5\n",
        "\n",
        "Write a function `init` that initializes the parameters of the GMM and returns `theta_0`, a NumPy array of shape $(3K, )$. The first $K$ elements of `theta_0` ($\\boldsymbol{\\theta}^{(0)}$) represents the means of the three mixtures, the next $K$ represent the variances and the last $K$ represent the mixture probabilities.\n",
        "\n",
        "The exact values to be used are as follows:\n",
        "\n",
        "- $\\mu_0 = 1, \\mu_1 = 2, \\mu_2 = 3$\n",
        "- $\\sigma_0^2 = \\sigma_1^2 = \\sigma_2^2 = 1$\n",
        "- $\\pi_0 = \\pi_1 = \\pi_2 = 1/3$\n",
        "\n",
        "Enter $||\\boldsymbol{\\theta}^{(0)}||$ as your answer correct to two decimal places. Keep this variable `theta_0` as it will be used in subsequent problems."
      ],
      "metadata": {
        "id": "YuhQSnp0BChl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "def init():\n",
        "  theta_0=np.array([1,2,3,1,1,1,1/3,1/3,1/3])\n",
        "  return theta_0\n",
        "print(init())\n",
        "print(f\"{np.linalg.norm(init()):.2f}\")"
      ],
      "metadata": {
        "id": "HKe2dspvIUgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404db6ce-dcb1-4a89-f795-eb40a3d83f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         2.         3.         1.         1.         1.\n",
            " 0.33333333 0.33333333 0.33333333]\n",
            "4.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-6\n",
        "\n",
        "Write a function `estep` that accepts `theta` and `X` as arguments. It should perform the E-step and return an array `lamb` of shape `(n, K)`. The element `lamb[i][k]` is equal to $\\lambda_k^{i}$. For the purposes of evaluation, run the function on `theta_0` and `X`. Call the returned value `lamb_1`.  Compute the sum of the zeroth column of the matrix `lamb_1` and enter that as your answer correct to two decimal places. Keep this variable `lamb_1` as it will be used in subsequent problems.\n",
        "\n",
        "\n",
        "**Aside**: We prefer the variable name `lamb` over `lambda` for a reason. Can you guess why?"
      ],
      "metadata": {
        "id": "EgsmXOKYJ76X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "def estep(theta, X):\n",
        "    n = X.shape[0]\n",
        "    K = theta.shape[0] // 3\n",
        "    means = theta[:K]\n",
        "    variances = theta[K:2*K]\n",
        "    weights = theta[2*K:]\n",
        "\n",
        "    lamb = np.zeros((n, K))\n",
        "\n",
        "    for i in range(n):\n",
        "        denominator = 0\n",
        "        for k in range(K):\n",
        "            # Calculate the probability density for the k-th mixture\n",
        "            pdf_k = (1 / np.sqrt(2 * np.pi * variances[k])) * np.exp(-(X[i] - means[k])**2 / (2 * variances[k]))\n",
        "            lamb[i][k] = weights[k] * pdf_k\n",
        "            denominator += lamb[i][k]\n",
        "\n",
        "        # Normalize the responsibilities\n",
        "        if denominator > 0:\n",
        "            lamb[i, :] /= denominator\n",
        "        else:\n",
        "            # Handle cases where denominator is zero (avoid division by zero)\n",
        "            lamb[i, :] = 1.0 / K # Assign equal responsibility\n",
        "\n",
        "    return lamb\n",
        "\n",
        "theta_0 = init()\n",
        "lamb_1 = estep(theta_0, X)\n",
        "print(f\"{np.sum(lamb_1[:, 0]):.2f}\")"
      ],
      "metadata": {
        "id": "kKH7zNZ6IJsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7605e74c-d265-43cd-eb73-fe6a0dbca19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-3716950152.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  lamb[i][k] = weights[k] * pdf_k\n",
            "/tmp/ipython-input-20-3716950152.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  lamb[i][k] = weights[k] * pdf_k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68226.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-7\n",
        "\n",
        "Write a function `mstep` that accepts `lamb` and `X` as arguments. It should perform the M-step and return a NumPy array `theta`, the updated parameters, namely. We follow the same convention for storing the parameters as was done during the init step. For the purposes of evaluation, compute the value of the function for `lamb_1` and `X`. Call the returned value `theta_1` ($\\boldsymbol{\\theta}^{(1)}$). Enter $||\\boldsymbol{\\theta}^{(1)}||$  as your answer correct to two decimal places."
      ],
      "metadata": {
        "id": "Fqnf831nLAlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "def mstep(lamb, X):\n",
        "    n, K = lamb.shape\n",
        "    means = np.zeros(K)\n",
        "    variances = np.zeros(K)\n",
        "    weights = np.zeros(K)\n",
        "\n",
        "    for k in range(K):\n",
        "        Nk = np.sum(lamb[:, k])\n",
        "        means[k] = np.sum(lamb[:, k] * X) / Nk\n",
        "        variances[k] = np.sum(lamb[:, k] * (X - means[k])**2) / Nk\n",
        "        weights[k] = Nk / n\n",
        "\n",
        "    theta = np.concatenate((means, variances, weights))\n",
        "    return theta\n",
        "\n",
        "theta_0 = init()\n",
        "lamb_1 = estep(theta_0, X)\n",
        "theta_1 = mstep(lamb_1, X)\n",
        "print(f\"{np.linalg.norm(theta_1):.2f}\")\n"
      ],
      "metadata": {
        "id": "k9FSc2QiITDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f073e266-e0ae-4bc5-8910-7c94ded30c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-3716950152.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  lamb[i][k] = weights[k] * pdf_k\n",
            "/tmp/ipython-input-20-3716950152.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  lamb[i][k] = weights[k] * pdf_k\n",
            "/tmp/ipython-input-20-3716950152.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  lamb[i][k] = weights[k] * pdf_k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.69\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.84401327,  1.0795422 ,  4.93145319,  4.99571036,  2.50234357,\n",
              "        3.8634084 ,  0.68226196,  0.13029543,  0.1874426 ])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_CyE3muycqT",
        "outputId": "d3ca6aee-d134-4879-dcd1-7c03033b3d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-8\n",
        "\n",
        "Given two vectors $\\boldsymbol{\\theta}^{(t)}$ and $\\boldsymbol{\\theta}^{(t + 1)}$, write a function `distance` that accepts these two vectors as arguments and returns the distance between them:\n",
        "\n",
        "$$\n",
        "||\\boldsymbol{\\theta}^{(t + 1)} - \\boldsymbol{\\theta}^{(t)}||\n",
        "$$\n",
        "\n",
        "For the purposes of evaluation, compute the distance between $\\boldsymbol{\\theta}^{(0)}$ and $\\boldsymbol{\\theta}^{(1)}$ and report your answer correct to two decimal places."
      ],
      "metadata": {
        "id": "0SLzBm4fLRSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "def distance(theta_t, theta_t_1):\n",
        "  return np.linalg.norm(theta_t_1-theta_t)\n",
        "print(distance(theta_1,theta_0))"
      ],
      "metadata": {
        "id": "f-dyb9_4IVwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3274df1-e66a-433d-e88e-780423132d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.480160553726957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-9\n",
        "\n",
        "Perform the EM algorithm until convergence. The stopping-criterion is that the distance between the two parameter-vectors should be less than $0.01$.\n",
        "\n",
        "$$\n",
        "||\\boldsymbol{\\theta}^{(t + 1)} - \\boldsymbol{\\theta}^{(t)}|| < 0.01\n",
        "$$\n",
        "\n",
        "\n",
        "Initialize the parameters to $\\boldsymbol{\\theta}^{(0)}$. Find the number of iterations it takes for the algorithm to converge. Enter this as your answer.\n",
        "\n",
        "This is going to take some time. Hold tight!"
      ],
      "metadata": {
        "id": "FFQwFcH6MELs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "theta_0=init()\n",
        "theta_1=mstep(estep(theta_0,X),X)\n",
        "iterations=1\n",
        "while distance(theta_0,theta_1)>0.01:\n",
        "  theta_0=theta_1\n",
        "  theta_1=mstep(estep(theta_0,X),X)\n",
        "  iterations+=1\n",
        "  if (iterations%10==0):\n",
        "    print(f\"Iter: {iterations}, Distance: {distance(theta_0,theta_1)}\")\n",
        "print(f\"{iterations}\")"
      ],
      "metadata": {
        "id": "lqRgxVx2IXMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f6655e-dd46-48c0-b65c-00e195c62c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 10, Distance: 0.05655269701476861\n",
            "Iter: 20, Distance: 0.09883940971630462\n",
            "Iter: 30, Distance: 0.11772407083704675\n",
            "Iter: 40, Distance: 0.11993141162395222\n",
            "Iter: 50, Distance: 0.08013911907658583\n",
            "Iter: 60, Distance: 0.034113054971596994\n",
            "Iter: 70, Distance: 0.01223613370529517\n",
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-10\n",
        "\n",
        "Let us now verify the correctness of our algorithm. We know the true parameters here:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\theta} = \\begin{bmatrix}\n",
        "-4\\\\\n",
        "0\\\\\n",
        "5\\\\\n",
        "2\\\\\n",
        "1\\\\\n",
        "3\\\\\n",
        "0.3\\\\\n",
        "0.5\\\\\n",
        "0.2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Let $\\boldsymbol{\\theta}^{*}$ be the parameter at convergence. Compute the distance between this vector and the true parameter vector. Enter your answer correct to two decimal places. The smaller the distance, better our estimate."
      ],
      "metadata": {
        "id": "zB33Rp_4awWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "known=[-4,0,5,2,1,3,0.3,0.5,0.2]\n",
        "print(distance(theta_1,known))\n",
        "print(theta_1)"
      ],
      "metadata": {
        "id": "WdfWCxQVbvBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cd589d-ed28-4d26-bfb3-f2a8ccd56fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10196573248897503\n",
            "[-3.94585325  0.02014348  5.00488842  2.06801305  0.96390146  3.0322972\n",
            "  0.30548887  0.49423046  0.20028068]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem-11\n",
        "\n",
        "We shall do a hard clustering of the data-points. Use the final `lamb` value obtained and cluster the points using:\n",
        "\n",
        "$$\n",
        "z_i = \\operatorname*{argmax} \\limits_{k} \\lambda_k^{i}\n",
        "$$\n",
        "\n",
        "Let $0$, $1$ and $2$ correspond to the colors red, blue and green respectively. Plot three colored histograms on the same figure, one for each cluster."
      ],
      "metadata": {
        "id": "oD5eJxOBMfN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Solution ###\n",
        "lamb=estep(theta_1,X)\n",
        "cluster_indices=np.argmax(lamb,axis=1)\n",
        "print(cluster_indices)\n",
        "plt.hist(X[cluster_indices==0],bins=1000,color='red',alpha=0.5)\n",
        "plt.hist(X[cluster_indices==1],bins=1000,color='blue',alpha=0.5)\n",
        "plt.hist(X[cluster_indices==2],bins=1000,color='green',alpha=0.5)"
      ],
      "metadata": {
        "id": "NwRMqRTQgWbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ead2130-39f6-4acb-d33c-5406e278b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 2 1 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([23., 27., 38., 22., 27., 27., 35., 19., 22., 28., 26., 28., 17.,\n",
              "        35., 21., 23., 26., 20., 20., 18., 20., 21., 20., 29., 23., 24.,\n",
              "        16., 22., 23., 28., 22., 34., 24., 24., 25., 30., 27., 26., 14.,\n",
              "        28., 20., 17., 20., 23., 29., 22., 24., 24., 28., 21., 25., 22.,\n",
              "        15., 21., 34., 22., 17., 27., 27., 16., 21., 33., 23., 23., 14.,\n",
              "        18., 25., 23., 18., 26., 25., 26., 20., 30., 20., 30., 25., 27.,\n",
              "        17., 25., 22., 22., 38., 29., 20., 31., 33., 33., 23., 20., 32.,\n",
              "        30., 33., 30., 35., 40., 29., 21., 24., 28., 24., 27., 19., 30.,\n",
              "        31., 23., 26., 29., 37., 32., 30., 29., 35., 25., 23., 29., 25.,\n",
              "        23., 29., 26., 36., 29., 36., 26., 37., 26., 31., 37., 40., 36.,\n",
              "        30., 26., 43., 29., 35., 28., 35., 41., 39., 31., 31., 24., 22.,\n",
              "        28., 39., 39., 35., 34., 39., 46., 42., 39., 36., 35., 31., 40.,\n",
              "        32., 43., 25., 37., 34., 27., 41., 35., 37., 30., 37., 29., 28.,\n",
              "        37., 38., 38., 61., 50., 31., 37., 44., 26., 36., 37., 45., 36.,\n",
              "        36., 49., 41., 28., 30., 37., 39., 37., 37., 30., 43., 46., 43.,\n",
              "        41., 46., 40., 40., 44., 33., 44., 40., 50., 46., 33., 32., 36.,\n",
              "        31., 43., 43., 36., 41., 48., 44., 33., 34., 38., 42., 51., 39.,\n",
              "        42., 35., 52., 43., 40., 39., 41., 32., 43., 44., 41., 42., 51.,\n",
              "        44., 55., 38., 46., 39., 49., 37., 35., 37., 30., 51., 50., 50.,\n",
              "        39., 46., 42., 51., 41., 40., 47., 49., 54., 50., 43., 43., 43.,\n",
              "        34., 42., 50., 47., 40., 41., 42., 38., 52., 39., 58., 48., 44.,\n",
              "        46., 40., 46., 45., 50., 45., 44., 43., 42., 49., 47., 48., 42.,\n",
              "        37., 43., 50., 40., 36., 37., 48., 36., 46., 40., 43., 44., 43.,\n",
              "        48., 59., 33., 43., 42., 36., 61., 45., 36., 56., 45., 32., 41.,\n",
              "        41., 33., 48., 52., 43., 52., 32., 36., 47., 38., 56., 50., 46.,\n",
              "        48., 41., 45., 67., 51., 50., 45., 46., 35., 43., 45., 45., 42.,\n",
              "        42., 62., 42., 44., 39., 53., 41., 50., 41., 56., 49., 36., 32.,\n",
              "        46., 48., 41., 49., 36., 35., 44., 43., 36., 35., 40., 33., 46.,\n",
              "        40., 32., 44., 26., 36., 32., 39., 40., 36., 53., 34., 46., 32.,\n",
              "        42., 42., 39., 39., 37., 43., 28., 30., 36., 45., 28., 34., 32.,\n",
              "        32., 30., 38., 42., 28., 43., 32., 39., 40., 30., 34., 27., 38.,\n",
              "        42., 34., 34., 31., 38., 33., 31., 27., 30., 45., 41., 44., 40.,\n",
              "        27., 38., 31., 27., 28., 39., 38., 28., 34., 32., 33., 22., 28.,\n",
              "        29., 28., 25., 37., 49., 27., 36., 27., 24., 19., 32., 27., 31.,\n",
              "        34., 22., 42., 21., 28., 21., 35., 29., 17., 22., 26., 24., 28.,\n",
              "        33., 22., 36., 26., 31., 27., 26., 30., 28., 23., 31., 24., 34.,\n",
              "        23., 28., 25., 28., 26., 29., 25., 26., 18., 26., 21., 24., 20.,\n",
              "        26., 31., 21., 18., 22., 26., 27., 27., 28., 33., 17., 18., 22.,\n",
              "        20., 21., 16., 20., 21., 15., 20., 22., 24., 18., 21., 18., 23.,\n",
              "        16., 24., 11., 15., 16., 19., 15., 27., 18., 18., 25., 23., 13.,\n",
              "        15., 15., 20., 20., 19., 25., 18., 14., 23., 16., 12.,  8., 12.,\n",
              "        12., 15., 22., 16., 12., 11., 19., 18., 16., 13., 14., 18.,  9.,\n",
              "        15., 11., 12., 13., 15., 13., 13., 13., 11., 19., 13., 13., 14.,\n",
              "        13., 10.,  9.,  9., 12., 21., 12.,  8., 15., 10.,  8.,  7., 11.,\n",
              "        11., 13., 20., 11., 13.,  5., 11., 11., 13., 11., 10., 11., 12.,\n",
              "        11.,  7., 12.,  9., 10.,  6.,  6., 15., 14., 11.,  8.,  9.,  6.,\n",
              "         9.,  8.,  8.,  7.,  8.,  2.,  9., 14.,  6., 10.,  7., 12.,  9.,\n",
              "         6.,  4.,  5.,  4.,  6., 18.,  6.,  7.,  6.,  3.,  8.,  5.,  4.,\n",
              "        10.,  4.,  9.,  6.,  6., 11.,  8., 11.,  4., 11.,  6.,  6.,  5.,\n",
              "         3.,  8.,  5.,  7.,  8.,  5.,  2.,  6.,  7., 10.,  6.,  5.,  7.,\n",
              "         1., 12.,  5.,  3.,  1.,  6.,  1.,  3.,  7.,  6.,  9.,  1.,  2.,\n",
              "         6.,  2.,  7.,  2.,  5.,  2.,  7.,  8.,  2.,  3.,  2.,  3.,  5.,\n",
              "         6.,  4.,  2.,  4.,  3.,  3.,  5.,  7.,  0.,  2.,  3.,  2.,  1.,\n",
              "         3.,  4.,  1.,  7.,  5.,  6.,  1.,  3.,  5.,  3.,  2.,  5.,  0.,\n",
              "         4.,  3.,  0.,  3.,  2.,  2.,  3.,  3.,  1.,  3.,  3.,  4.,  4.,\n",
              "         3.,  2.,  1.,  4.,  1.,  3.,  0.,  3.,  2.,  1.,  1.,  2.,  0.,\n",
              "         2.,  5.,  1.,  0.,  1.,  1.,  1.,  1.,  2.,  2.,  5.,  1.,  0.,\n",
              "         2.,  1.,  0.,  0.,  3.,  2.,  3.,  1.,  0.,  1.,  1.,  2.,  3.,\n",
              "         3.,  2.,  1.,  2.,  1.,  3.,  0.,  0.,  2.,  1.,  2.,  0.,  1.,\n",
              "         1.,  2.,  1.,  2.,  1.,  2.,  1.,  0.,  0.,  1.,  1.,  2.,  2.,\n",
              "         1.,  2.,  3.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
              "         2.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
              "         0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
              "         1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
              "         1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
              " array([ 2.2960849 ,  2.30581649,  2.31554807, ..., 12.00821062,\n",
              "        12.01794221, 12.0276738 ]),\n",
              " <BarContainer object of 1000 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}